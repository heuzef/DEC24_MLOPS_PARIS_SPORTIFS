{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation du serveur de tracking MLflow du projet\n",
    "\n",
    "Le serveur de tracking MLFlow est accessible √† l'adresse suivante : https://parivision.heuzef.com:5000\n",
    "\n",
    "Ce notebook explique comment utiliser ce dernier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports librairies et secrets\n",
    "import mlflow\n",
    "from mlflow.server import get_app_client\n",
    "import requests\n",
    "import setuptools\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")\n",
    "username = os.getenv('MLFLOW_TRACKING_USERNAME')\n",
    "password = os.getenv('MLFLOW_TRACKING_PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisateur : parivision\n",
      "Est admin : True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/814265185531092965', creation_time=1741090978662, experiment_id='814265185531092965', last_update_time=1741090978662, lifecycle_stage='active', name='parivision', tags={}>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connexion au serveur\n",
    "mlflow_uri = \"http://parivision.heuzef.com:5000\" # L'adresse du serveur MLFlow'\n",
    "client = get_app_client(\"basic-auth\", tracking_uri=mlflow_uri)\n",
    "\n",
    "print(f\"Utilisateur : {client.get_user(\"parivision\").username}\")\n",
    "print(f\"Est admin : {client.get_user(\"parivision\").is_admin}\")\n",
    "\n",
    "mlflow.set_tracking_uri(mlflow_uri)\n",
    "mlflow.set_experiment(\"parivision\") # Le nom du projet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V√©rifier la disponibilit√©\n",
    "\n",
    "Dans un premier temps, il faut s'assurer que le serveur est bien joignable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le serveur de tracking MLflow est disponible ! Youpi !  http://parivision.heuzef.com:5000\n",
      "Message : <!doctype html><html lang=\"en\"><head><meta charset=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width,initial-scale=1,shrink-to-fit=no\"/><link rel=\"shortcut icon\" href=\"./static-files/favicon.ico\"/><meta name=\"theme-color\" content=\"#000000\"/><link rel=\"manifest\" href=\"./static-files/manifest.json\" crossorigin=\"use-credentials\"/><title>MLflow</title><script defer=\"defer\" src=\"static-files/static/js/main.3e6a54ef.js\"></script><link href=\"static-files/static/css/main.fd7f2361.css\" rel=\"stylesheet\"></head><body><noscript>You need to enable JavaScript to run this app.</noscript><div id=\"root\"></div><div id=\"modal\"></div></body></html>\n"
     ]
    }
   ],
   "source": [
    "# Effectuer une requ√™te\n",
    "response = requests.get(\n",
    "    f\"{mlflow_uri}/\",\n",
    "    auth=(username, password)\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Le serveur de tracking MLflow est disponible ! Youpi ! \", mlflow_uri)\n",
    "    print(\"Message :\", response.text)\n",
    "else:\n",
    "    print(f\"√âchec de la connexion. Code d'erreur : {response.status_code}\")\n",
    "    print(\"Message :\", response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement d'un mod√®le pour l'exemple\n",
    "\n",
    "Nous allons entrainer un petit mod√®le basique, avec Scikit-learn, pour obtenir quelques m√©triques qui seront enregistr√©s dans des variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Voici des informations d'exemple que nous souhaiterions envoyer sur le serveur MLFlow :\n",
      "\n",
      "\n",
      "metrics :\n",
      "{'mae': 51.99824921798891, 'mse': 4387.742421525984, 'rmse': np.float64(66.24003639435884), 'r2': 0.8654539293255742}\n",
      "\n",
      "params :\n",
      "{'n_estimators': 10, 'max_depth': 10, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "# Imports librairies\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import d'une database (au pif juste pour ce test)\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/DataScientest/MLflow_Course/refs/heads/main/data/fake_data.csv\")\n",
    "X = data.drop(columns=[\"date\", \"demand\"])\n",
    "y = data[\"demand\"]\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "params = {\n",
    "    \"n_estimators\": 10,\n",
    "    \"max_depth\": 10,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "rf = RandomForestRegressor(**params)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = rf.predict(X_val)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "metrics = {\"mae\": mae, \"mse\": mse, \"rmse\": rmse, \"r2\": r2}\n",
    "\n",
    "print(\"\\nVoici des informations d'exemple que nous souhaiterions envoyer sur le serveur MLFlow :\\n\")\n",
    "\n",
    "print(\"\\nmetrics :\")\n",
    "print(metrics)\n",
    "\n",
    "print(\"\\nparams :\")\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Envoi des informations au serveur MLflow\n",
    "\n",
    "Maintenant que nous avons nos resultats, nous allons donc cr√©er une \"run\" et la transf√©rer sur le serveur. \n",
    "\n",
    "Pour cet exemple, c'est le module mlflow.sklearn qui est utilis√©. Il vous faudra bien sur utiliser celui adapt√© √† votre outil : https://mlflow.org/docs/latest/python_api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heuzef/GIT/DEC24_MLOPS_PARIS_SPORTIFS/.venv/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run test_001 at: http://parivision.heuzef.com:5000/#/experiments/814265185531092965/runs/172c48b7a3eb455db61ba84b2011f70a\n",
      "üß™ View experiment at: http://parivision.heuzef.com:5000/#/experiments/814265185531092965\n"
     ]
    }
   ],
   "source": [
    "run_name = \"test_002\" # Le nom de la run, nous utiliserons notre propre nomenclature pour le projet\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(sk_model=rf, input_example=X_val, artifact_path=run_name+\"_artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code execut√© en fin de script ou fin de notebook est finalement suffisant et assez flexible pour transf√©rer les informations que nous souhaitons. Mais il est possible de faire encore plus simple en laissant MLflow se debrouiller avec `mlflow.autolog()`.\n",
    "\n",
    "> https://mlflow.org/docs/latest/tracking/autolog.html\n",
    "\n",
    "N'h√©sitez pas √† tester des hyper-param√®tres et envoyer quelques m√©triques √† comparer sur l'interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charger le mod√®le le plus performant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ici, nous allons simplement charger la meilleur version du mod√®le, rep√©r√© gr√¢ce a son alias \"Champion\".\n",
    ">\n",
    "> http://parivision.heuzef.com:5000/#/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: test_001_artifacts\n",
       "  flavor: mlflow.sklearn\n",
       "  run_id: 172c48b7a3eb455db61ba84b2011f70a"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "champion = mlflow.pyfunc.load_model(f\"models:/parivision@champion\")\n",
    "\n",
    "champion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1012.77094831, 1455.76527377,  931.17489626, 1327.67841297,\n",
       "        951.93013   ,  896.20498834, 1186.90646238, 1251.68361962,\n",
       "        933.77154864,  983.47213966])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = champion.predict(X_val)\n",
    "display(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=100x100 at 0x7F75EF899BE0>\n",
      "üèÉ View run resilient-crab-523 at: http://parivision.heuzef.com:5000/#/experiments/814265185531092965/runs/5cd76ec0a0704577b8ce8e3637afebcd\n",
      "üß™ View experiment at: http://parivision.heuzef.com:5000/#/experiments/814265185531092965\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "artifact_uri=\"/mlartifacts\"\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    image = Image.new(\"RGB\", (100, 100))\n",
    "    artifact_uri = run.info.artifact_uri\n",
    "    mlflow.log_image(image, \"image.png\")\n",
    "    image = mlflow.artifacts.load_image(artifact_uri + \"/image.png\")\n",
    "    print(image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
